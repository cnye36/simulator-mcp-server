# Simulation MCP Server

A stateless Model Context Protocol (MCP) server for running scientific simulations. Perfect for integrating simulation capabilities into chat applications, interactive dashboards, and AI-powered tools.

## ğŸ¯ Overview

This MCP server provides a **stateless compute service** that runs simulations and returns results. It's designed to be integrated into chat applications where:

- âœ… Your chat app handles authentication and user data
- âœ… The MCP server performs computations
- âœ… Results are returned as JSON for immediate use or storage

**Key Features:**
- ğŸš€ **Stateless Operation** - No authentication, no user data storage
- âš¡ **Fast Preview Mode** - Optimized for real-time interactive UIs (~50-100ms)
- ğŸ“Š **JSON Data Return** - Get simulation data directly, no file downloads needed
- ğŸ”§ **Multiple Models** - Support for epidemiology, physics, finance, and custom models
- ğŸ“ˆ **Comprehensive Logging** - Full request/response logging for debugging
- ğŸŒ **HTTP Transport** - Standard MCP protocol over HTTP

## ğŸ“‹ Table of Contents

- [Quick Start](#quick-start)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [API Reference](#api-reference)
- [Deployment](#deployment)
- [Architecture](#architecture)
- [Documentation](#documentation)

## ğŸš€ Quick Start

### Local Development

```bash
# Clone the repository
git clone <repository-url>
cd simulation-mcp-server

# Install dependencies
pip install -r requirements.txt

# Run in stdio mode (for local development)
python server.py
```

### Docker

```bash
# Build and run with Docker Compose
docker compose up --build

# Health check
curl http://localhost:8000/health
```

### Example Request

```bash
curl -X POST http://localhost:8000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "simulate_model",
      "arguments": {
        "domain": "epidemiology",
        "model_type": "SIR",
        "parameters": {"beta": 0.3, "gamma": 0.1},
        "initial_conditions": {"S": 0.99, "I": 0.01, "R": 0},
        "time_span": {
          "start": 0,
          "end": 160,
          "steps": 400,
          "preview_mode": true
        },
        "return_data": true,
        "save_artifacts": false
      }
    }
  }'
```

## âœ¨ Features

### Core Capabilities

- **Multiple Simulation Models**: Currently supports SIR (epidemiology), with support for Lotka-Volterra, Logistic, Projectile, and Monte Carlo models planned
- **Flexible Time Grids**: Configurable time spans with preview mode for fast rendering
- **Multiple Solvers**: RK45, RK23, and DOP853 integration methods
- **Sensitivity Analysis**: Optional one-way sensitivity analysis support
- **Metrics Calculation**: Automatic calculation of key metrics (peak values, timing, etc.)

### Performance Optimizations

- **Preview Mode**: Reduces data points to 100 for ~50-100ms response times
- **Optional Artifacts**: Skip CSV/PNG generation for faster responses
- **JSON Data Return**: Get simulation data directly without file I/O overhead

### Production Ready

- **Health Check Endpoint**: `/health` for deployment monitoring
- **Comprehensive Logging**: Full request/response logging with configurable levels
- **Error Handling**: Detailed error messages with stack traces
- **Docker Support**: Ready-to-use Dockerfile and docker-compose.yml
- **Render Deployment**: Pre-configured `render.yaml` for easy deployment

## ğŸ“¦ Installation

### Requirements

- Python 3.12+
- pip or uv

### Dependencies

```bash
pip install -r requirements.txt
```

Key dependencies:
- `mcp[cli]>=1.2.0` - Model Context Protocol SDK
- `pydantic>=2.7` - Data validation
- `numpy>=1.26` - Numerical computations
- `scipy>=1.11` - Scientific computing and ODE solvers
- `matplotlib>=3.8` - Plot generation (optional, for artifacts)

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `MCP_TRANSPORT` | `stdio` | Transport mode (`streamable-http` for production) |
| `STORAGE_PATH` | `./storage` | Directory for saving artifacts |
| `PORT` | `8000` | Server port |
| `FASTMCP_HOST` | `0.0.0.0` | Host to bind to (use `0.0.0.0` for external access) |
| `LOG_LEVEL` | `INFO` | Logging verbosity (`DEBUG`, `INFO`, `WARNING`, `ERROR`) |

## ğŸ’» Usage

### Basic Simulation

```python
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# Connect to server
async with stdio_client(StdioServerParameters(
    command="python",
    args=["server.py"]
)) as (read, write):
    async with ClientSession(read, write) as session:
        # Run simulation
        result = await session.call_tool(
            "simulate_model",
            arguments={
                "domain": "epidemiology",
                "model_type": "SIR",
                "parameters": {"beta": 0.3, "gamma": 0.1},
                "initial_conditions": {"S": 0.99, "I": 0.01, "R": 0},
                "time_span": {
                    "start": 0,
                    "end": 160,
                    "steps": 400
                },
                "return_data": True
            }
        )
        
        print(result.content[0].text)
```

### Interactive UI Mode (Fast Preview)

```python
# Optimized for real-time slider interactions
result = await session.call_tool(
    "simulate_model",
    arguments={
        # ... parameters ...
        "time_span": {
            "start": 0,
            "end": 160,
            "steps": 600,
            "preview_mode": True  # Limits to 100 points
        },
        "return_data": True,
        "save_artifacts": False  # Skip file generation
    }
)
```

### High-Quality Export Mode

```python
# Full resolution with artifacts
result = await session.call_tool(
    "simulate_model",
    arguments={
        # ... parameters ...
        "time_span": {
            "start": 0,
            "end": 160,
            "steps": 1000,
            "preview_mode": False
        },
        "return_data": True,
        "save_artifacts": True  # Generate CSV and PNG files
    }
)
```

## ğŸ“š API Reference

### Tool: `simulate_model`

Run a simulation with specified parameters and return results.

#### Input Parameters

```typescript
{
  domain: "epidemiology" | "physics" | "finance" | "custom",
  model_type: "SIR" | "LotkaVolterra" | "Logistic" | "Projectile" | "MonteCarlo",
  parameters: { [key: string]: number },  // Model-specific parameters
  initial_conditions: { [key: string]: number },  // Initial state values
  time_span: {
    start: number,      // Start time
    end: number,        // End time
    steps: number,      // Number of time points (>= 2)
    preview_mode?: boolean  // Limit to 100 points for speed
  },
  method?: "RK45" | "RK23" | "DOP853",  // ODE solver method (default: "RK45")
  sensitivity?: { [key: string]: number },  // Optional sensitivity analysis
  tags?: string[],  // Optional tags for organization
  return_data?: boolean,  // Return data points in response (default: true)
  save_artifacts?: boolean  // Save CSV/PNG files (default: false)
}
```

#### Output Format

```typescript
{
  status: "success" | "error",
  message: string,
  summary?: string,  // Human-readable summary
  metrics: {
    [key: string]: number  // Calculated metrics (e.g., I_peak, t_peak)
  },
  columns: string[],  // Column names (e.g., ["t", "S", "I", "R"])
  data?: Array<{     // Time series data points
    t: number,
    [state_var: string]: number
  }>,
  artifacts: Array<{
    kind: "csv" | "plot" | "json",
    path: string
  }>
}
```

#### Example: SIR Model

**Input:**
```json
{
  "domain": "epidemiology",
  "model_type": "SIR",
  "parameters": {
    "beta": 0.3,   // Transmission rate
    "gamma": 0.1   // Recovery rate
  },
  "initial_conditions": {
    "S": 0.99,     // Susceptible
    "I": 0.01,     // Infected
    "R": 0.0       // Recovered
  },
  "time_span": {
    "start": 0,
    "end": 160,
    "steps": 400,
    "preview_mode": false
  },
  "return_data": true,
  "save_artifacts": false
}
```

**Output:**
```json
{
  "status": "success",
  "message": "Simulation completed",
  "summary": "Peak infection 0.3743 at t â‰ˆ 33.89",
  "metrics": {
    "I_peak": 0.3743,
    "t_peak": 33.89
  },
  "columns": ["t", "S", "I", "R"],
  "data": [
    {"t": 0.0, "S": 0.99, "I": 0.01, "R": 0.0},
    {"t": 0.4, "S": 0.9896, "I": 0.0102, "R": 0.0002},
    // ... more data points
  ],
  "artifacts": []
}
```

### Health Check Endpoint

**GET** `/health`

Returns server status and configuration:

```json
{
  "status": "healthy",
  "service": "simulation-mcp",
  "version": "0.1.0",
  "storage": "/tmp/storage",
  "solvers": 1
}
```

## ğŸš€ Deployment

### Docker Deployment

```bash
# Build image
docker build -t simulation-mcp-server .

# Run container
docker run -p 8000:8000 \
  -e MCP_TRANSPORT=streamable-http \
  -e PORT=8000 \
  -e FASTMCP_HOST=0.0.0.0 \
  simulation-mcp-server
```

### Render Deployment

1. **Connect GitHub Repository** to Render
2. **Render auto-detects** `render.yaml` configuration
3. **Set Environment Variables** (if needed):
   - `MCP_TRANSPORT=streamable-http`
   - `PORT=8000`
   - `FASTMCP_HOST=0.0.0.0`
4. **Deploy** - Render handles the rest!

The `render.yaml` file is pre-configured with:
- Docker-based deployment
- Health check endpoint
- Stateless operation (no persistent disk needed)
- Environment variables

### Other Platforms

The server can be deployed to any platform that supports:
- Python 3.12+
- HTTP/HTTPS endpoints
- Environment variable configuration

Examples: Heroku, Railway, Fly.io, AWS ECS, Google Cloud Run, etc.

## ğŸ—ï¸ Architecture

### Design Philosophy

This MCP server is **stateless** - it performs computations and returns results. It does NOT:
- âŒ Store user data
- âŒ Handle authentication
- âŒ Manage user sessions
- âŒ Persist simulation results

**Your application should handle:**
- âœ… User authentication (e.g., via Supabase)
- âœ… Chat history and context
- âœ… Storing simulation results (if needed)
- âœ… User-specific data management

### Request Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Chat App (Supabase)      â”‚
â”‚   - User authenticated          â”‚
â”‚   - Chat context stored         â”‚
â”‚   - User wants simulation       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP POST
               â”‚ (No auth needed)
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Server (Stateless)        â”‚
â”‚   - Receives parameters         â”‚
â”‚   - Runs simulation             â”‚
â”‚   - Returns JSON data           â”‚
â”‚   - No storage, no auth         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ JSON Response
               â”‚ (data + metrics)
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Chat App                 â”‚
â”‚   - Receives results            â”‚
â”‚   - Stores in Supabase (optional)â”‚
â”‚   - Displays to user            â”‚
â”‚   - Manages user context        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Storage Strategy

**Recommended Approach:**
1. Call MCP server with `return_data: true` and `save_artifacts: false`
2. Receive JSON data directly
3. Store in your own database (e.g., Supabase) if needed
4. Generate files client-side if exports are needed

See `ARCHITECTURE.md` for detailed integration patterns and Supabase schema examples.

## ğŸ“– Documentation

Comprehensive documentation is available in the `docs/` directory:

- **[ARCHITECTURE.md](./ARCHITECTURE.md)** - Detailed architecture and integration patterns
- **[docs/FEATURES_SUMMARY.md](./docs/FEATURES_SUMMARY.md)** - Complete feature list
- **[docs/DEPLOYMENT.md](./docs/DEPLOYMENT.md)** - Deployment guides
- **[docs/INTERACTIVE_UI_GUIDE.md](./docs/INTERACTIVE_UI_GUIDE.md)** - Frontend integration examples
- **[docs/LOGGING_GUIDE.md](./docs/LOGGING_GUIDE.md)** - Troubleshooting with logs
- **[docs/HTTP_TRANSPORT_SETUP.md](./docs/HTTP_TRANSPORT_SETUP.md)** - HTTP transport configuration
- **[docs/CONNECTING_AI_APP.md](./docs/CONNECTING_AI_APP.md)** - Connecting AI applications

## ğŸ”§ Development

### Project Structure

```
simulation-mcp-server/
â”œâ”€â”€ server.py              # Main MCP server implementation
â”œâ”€â”€ models/                # Simulation model implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ sir.py            # SIR epidemiology model
â”œâ”€â”€ schemas/               # JSON schemas for validation
â”‚   â””â”€â”€ simulate_model_input.json
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ Dockerfile             # Docker configuration
â”œâ”€â”€ docker-compose.yml     # Docker Compose setup
â”œâ”€â”€ render.yaml            # Render deployment config
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md             # This file
```

### Adding New Models

1. Create a new model file in `models/` (e.g., `models/lotka_volterra.py`)
2. Implement the solver function:
   ```python
   def simulate_lotka_volterra(
       parameters: Dict[str, float],
       y0: Dict[str, float],
       tspan: Tuple[float, float],
       steps: int,
       method: str = "RK45"
   ) -> Tuple[np.ndarray, np.ndarray, Dict[str, float]]:
       # Implementation
       return t, Y, metrics
   ```
3. Register in `server.py`:
   ```python
   SOLVERS = {
       ("epidemiology", "SIR"): simulate_sir,
       ("epidemiology", "LotkaVolterra"): simulate_lotka_volterra,
       # ...
   }
   ```
4. Update JSON schema in `schemas/simulate_model_input.json`

### Running Tests

```bash
# Run server in stdio mode for testing
python server.py

# Test with curl (HTTP mode)
curl http://localhost:8000/health
```

### Logging

Logging is comprehensive and configurable:

```bash
# Set log level
export LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR

# Run server
python server.py
```

Logs include:
- Request parameters
- Execution times
- Data shapes and metrics
- Error stack traces

## ğŸ“Š Performance Benchmarks

| Mode | Steps | Preview | Artifacts | Data Return | Response Time |
|------|-------|---------|-----------|-------------|---------------|
| Interactive | 600 | âœ… Yes | âŒ No | âœ… Yes | ~50-100ms |
| Standard | 600 | âŒ No | âŒ No | âœ… Yes | ~150-200ms |
| Full Quality | 1000 | âŒ No | âœ… Yes | âœ… Yes | ~300-500ms |
| File Only | 600 | âŒ No | âœ… Yes | âŒ No | ~250-400ms |

*Measured on Render Starter tier (0.5 CPU, 512 MB RAM)*

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- Additional simulation models (Lotka-Volterra, Logistic, Projectile, Monte Carlo)
- Sensitivity analysis enhancements
- Performance optimizations
- Documentation improvements

## ğŸ“ License

[Add your license here]

## ğŸ†˜ Support

For issues, questions, or contributions:

1. Check the [documentation](./docs/) directory
2. Review logs with `LOG_LEVEL=DEBUG`
3. Check [ARCHITECTURE.md](./ARCHITECTURE.md) for integration patterns
4. See [docs/LOGGING_GUIDE.md](./docs/LOGGING_GUIDE.md) for troubleshooting

## ğŸ‰ Status

**Production Ready!** âœ…

- [x] HTTP transport configured
- [x] Health check endpoint
- [x] Data returned in JSON format
- [x] Preview mode for performance
- [x] Comprehensive logging
- [x] Docker containerization
- [x] Render deployment config
- [x] Documentation complete
- [x] Error handling improved

---

**Happy Simulating! ğŸš€**

